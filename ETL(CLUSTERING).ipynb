{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8sN4BdQiMz_"
      },
      "source": [
        "Lo primero que hacemos en el proceso de ETL de este proyecto es cargar el csv, lo cargaremos con polars usando un read_csv y lo cargaremos con el codigo ISO.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3YfeWoWiEgc",
        "outputId": "53c39d9d-d31d-43af-d663-5813f4746de1"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "\n",
        "df = pl.read_csv(\"data.csv\", encoding=\"ISO-8859-1\", infer_schema_length=10000)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T8E1Bq0iEge"
      },
      "source": [
        "\n",
        "Ahora sobre el dataset vamos a analizar si hay datos que limpiar:\n",
        "\n",
        "Primero comprobaremos si el dataset contiene valores nulos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0yzfeRZiEgf",
        "outputId": "b8f270bc-6a0f-48f6-f540-b9fd8ba2bca0"
      },
      "outputs": [],
      "source": [
        "df.null_count()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PtPc_n0iEgf"
      },
      "source": [
        "Como vemos hay muchos nulls, dado que el objetivo es agrupar por tipo de clientes el custumerID es esencial y no podemos tabajar sin el. y la descripcion seguramente la ignoremos, por que lo mas util a la hora de agrupar por cliente es la cantidad comprada, el valor total de gasto  y pais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-e9TN-XiEgg",
        "outputId": "f53391dc-5d77-4289-fb25-245614b3c715"
      },
      "outputs": [],
      "source": [
        "df = df.filter(df[\"Description\"].is_not_null())\n",
        "df = df.filter(df[\"CustomerID\"].is_not_null())\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKEJ5zB-iEgg"
      },
      "source": [
        "Habiendonos desecho de todos los datos con valores nulos seguiremos con los valores duplicados de todas las columnas, que tambien es importante por si a la hora de insertar los datos se cometio el error de añadir la misma compra dos veces, con lo cual no nos seria util para nuestra posterior predicción."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lu7Y5gxriEgg",
        "outputId": "b677f2af-e808-4082-cea7-4979598f9783"
      },
      "outputs": [],
      "source": [
        "\n",
        "f\"Filas duplicadas: {df.height - df.unique().height}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwyTFLlViEgg"
      },
      "source": [
        "En nuestro caso elimineramos estas filas duplicadas y, como mencionamos anteriormente, es muy probable que se trate de un error de la aplicacion al insertar datos y nos perjudique a la hora de hacer las predicciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OhUoupQiEgh",
        "outputId": "6beb688d-d0f6-4c6e-854a-b615e8a1acdc"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = df.unique()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg0MECIWiEgh"
      },
      "source": [
        "Ahora iremos con los valores negativos tanto en la columna de Quantity como en el UnitPrice, ya que serian los unicos que podrian tener unos valores negativos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3wa-jr2iEgh",
        "outputId": "da9258b2-0d38-4db2-b09f-1fcbe43b24f3"
      },
      "outputs": [],
      "source": [
        "df.filter((pl.col(\"Quantity\") < 0) | (pl.col(\"UnitPrice\") < 0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3CDILBLiEgh"
      },
      "source": [
        "En este caso vemos que hay valores negativos en estas dos columnas, se podrian interpretar como devoluciones de los productos, pero en este caso no los vamos a usar de esta forma porque no tendria sentido contar con estos valores si solo queremos calcular las ventas y no devoluciones. Asi que los tendremos que eliminar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aC_RPE8OiEgh",
        "outputId": "77276cb2-b592-4bcf-abf3-1dde25217cb2"
      },
      "outputs": [],
      "source": [
        "df = df.filter(~((pl.col(\"Quantity\") < 0) | (pl.col(\"UnitPrice\") < 0)))\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M60htNkiEgh"
      },
      "source": [
        "Es el turno de la fecha de facturacion, vamos a transformar la columna a tipo date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnbcfF7qiEgi",
        "outputId": "0ebdffce-1d03-4273-a7b0-fa21f64a0681"
      },
      "outputs": [],
      "source": [
        "df = df.with_columns(pl.col(\"InvoiceDate\").str.strptime(pl.Date, \"%m/%d/%Y %H:%M\"))\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DbC0IkgiEgi"
      },
      "source": [
        "Lo siguiente sera buscar algun outliers, para evitar la distorsion de los patrones, la no normalizacion de los datos y que no afecten a la precisión del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZ-g0w_MiEgi",
        "outputId": "f1c6268c-001d-4232-bcb8-ad7179e43049"
      },
      "outputs": [],
      "source": [
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JTEWGu2B6Wq"
      },
      "source": [
        "no vamos a liminar las compras que tengan precio de 0, porque entendemos que son regalos de la tienda y ademas nos puede venir bien para agrupar clientes que solo compren cuando hay cosas gratuitas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctuFDKpjiEgi"
      },
      "source": [
        "Siguiendo con las cosas un poco raras que habiamos detectado, en la columna Country habiamos visto un \"unspecified\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlQHJpr2iEgi",
        "outputId": "76ea206d-5880-4653-dc2d-629ea93e5dba"
      },
      "outputs": [],
      "source": [
        "df.filter(pl.col(\"Country\") == \"Unspecified\" )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0Ep7WULiEgi"
      },
      "source": [
        "Como en nuestro caso nos parece util y queremos llegar a agrupar las ventas por paises debemos eliminar las filas que contengan \"Unspecified\" en la columna Country."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBneF_PNiEgj",
        "outputId": "601f0220-bc46-4e76-a9ad-969199bdaf30"
      },
      "outputs": [],
      "source": [
        "df = df.filter(pl.col(\"Country\") != \"Unspecified\" )\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgZQoVMfiEgj"
      },
      "source": [
        "Algo raro tambien es que habia valores maximos muy altos en la cantidad y en el precio, es decir tenemos claramente outliers que habiamos detectado antes. Para solucionar esto usaremos la formula del IQR para ddefinir un limite superior e inderior en los valores.\n",
        "los modelos de agrupacion son muy sensibles a los outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tzh57tRtiEgj",
        "outputId": "5bca8392-be9e-4bb8-a25d-94141b7d7621"
      },
      "outputs": [],
      "source": [
        "def calc_iqr_from_column_name(name:str)-> None:\n",
        "    Q1 = df[name].quantile(0.25)\n",
        "    Q3 = df[name].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    print(f\"\\nIQR for {name}\")\n",
        "    print(Q1, Q3, IQR, lower_bound, upper_bound)\n",
        "\n",
        "calc_iqr_from_column_name(\"Quantity\")\n",
        "calc_iqr_from_column_name(\"UnitPrice\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQAlFrCSiEgj",
        "outputId": "980263b3-3fae-42f6-df63-29da6e06ff21"
      },
      "outputs": [],
      "source": [
        "upper_bound_limit_condition = (pl.col(\"Quantity\") > 27) | (pl.col(\"UnitPrice\") > 7.5)\n",
        "\n",
        "df.filter(upper_bound_limit_condition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHflIgtsiEgj"
      },
      "source": [
        "LLevando a cabo esta accion estariamos eliminando bastantes datos, pero la parte positiva es que estariamos normalizando lo maximo posible el flujo de los datos, entonces procederemos a eliminarlos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UnCdDyTiEgj",
        "outputId": "b69545af-e436-4835-a5f3-74e0afd79843"
      },
      "outputs": [],
      "source": [
        "df = df.filter(~((pl.col(\"Quantity\") > 27) | (pl.col(\"UnitPrice\") > 7.5)))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEfpi3bxiEgj",
        "outputId": "059ff27e-ae58-424d-a9af-6796f60a7d48"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_OFU-wGiEgj"
      },
      "source": [
        "Viendo que el objetivo es agrupar en diferentes tipos de clientes eliminaremos las columnas que no son relevantes\n",
        "\n",
        "CustomerID,InvoiceDate,Quantity, UnitPrice,InvoiceNo, Country: serian las columnas mas interesantes para nuestro modelo de clustering, teniendo en cuenta que country seria opcional y solo seria util si queremos segmentar internacionalmente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej_wN3lOiEgj",
        "outputId": "096ea066-c944-4ede-c8f5-e31de8ee0b45"
      },
      "outputs": [],
      "source": [
        "df = df[\"CustomerID\",\"InvoiceDate\",\"Quantity\", \"UnitPrice\",\"Country\",\"InvoiceNo\"]\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJzyC7MOiEgj"
      },
      "source": [
        "Ahora es el turno de las columnas extra.\n",
        "Hemos pensado las siguientes:\n",
        "\n",
        "TotalPrice ->  Para saber cuanto gastan los clientes.\n",
        "Last_buy ->  Días desde la última compra.\n",
        "Frequency ->  Número de compras (facturas únicas) por cliente.\n",
        "Monetary -> Suma del gasto total por cliente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTHZaBjZB6Wr"
      },
      "source": [
        "Creando la variable de totalPrice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RJKVy5LiEgj",
        "outputId": "75b9a2e0-6656-4817-f287-5bcd2c2da5a2"
      },
      "outputs": [],
      "source": [
        "df = df.with_columns(\n",
        "    (pl.col(\"Quantity\") * pl.col(\"UnitPrice\")).alias(\"TotalPrice\")\n",
        ")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZASaloBB6Wr"
      },
      "source": [
        "ahora Last_buy, frequency y monetary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VUtGrUsiEgk"
      },
      "source": [
        "Ahora agruparemos por dias para ver la suma de todas las ventas totales. De esta forma tendremos una mejor visualizacion de todas las ventas totales en cada dia que se han realizado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULyE1DTQiEgk",
        "outputId": "a4472f6c-2942-4f46-c58a-4394a490da2e"
      },
      "outputs": [],
      "source": [
        "max_date = df.select(pl.col(\"InvoiceDate\").max()).to_series()[0]\n",
        "\n",
        "df = df.group_by(\"CustomerID\").agg([\n",
        "\n",
        "    ((pl.lit(max_date) - pl.col(\"InvoiceDate\").max()) / pl.duration(days=1)).alias(\"Last_buy\"),\n",
        "\n",
        "\n",
        "    pl.col(\"InvoiceNo\").n_unique().alias(\"Frequency\"),\n",
        "\n",
        "\n",
        "    pl.col(\"TotalPrice\").sum().alias(\"Monetary\")\n",
        "])\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAEaUA3QB6Ws"
      },
      "source": [
        "Ahora es el turno de otro describe con las nuevas variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sV5T3KdXB6Ws",
        "outputId": "37042b5f-823b-4096-c1b5-4abdbbbb06cb"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIHI9VdjB6Ws"
      },
      "source": [
        "como vemos en monatery y en frequency tenemos claramente outliers, aplicaremos el logaritmo para no perder informacion y reducir la gran diferencia que hay, eso si tenemos que tener cuidado con los ceros\n",
        "\n",
        "no lo aplicaremos sobre last_buy porque no tiene una destribucion tan extrema como monetary o frequency y los dias son mas uniformes lo que puede probocar que el logaritmo distorsione la interpretacion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmrVtbmrB6Ws",
        "outputId": "9f24a302-6dbd-4a4f-e7cd-76ea52860d89"
      },
      "outputs": [],
      "source": [
        "df = df.filter(df[\"Monetary\"]>0)\n",
        "df = df.with_columns(\n",
        "    (pl.col(\"Monetary\") + 1).log().alias(\"Monetary_log\"),\n",
        "    (pl.col(\"Frequency\") + 1).log().alias(\"Frequency_log\")\n",
        ")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZhSKmmFB6Ws"
      },
      "source": [
        "Con esto tendriamos casi listo el proceso de ETL\n",
        "\n",
        "Faltaria hacer algunos pasos que son recomendados como el escalado dde variables ya que las metricas estan en escalas muy diferentes.\n",
        "\n",
        "y una gran diferencia en a escala afecta al clustering\n",
        "usaremos un standarscaler, tambien prodiamos usar el minmaxscaler o el Z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoawcybCiEgk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = df.select([\"Last_buy\", \"Frequency_log\", \"Monetary_log\"]).to_numpy()\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C05GNYlOB6Ws",
        "outputId": "6dbd00db-f0d6-44f7-a3cf-92c2001b3ce4"
      },
      "outputs": [],
      "source": [
        "df = df.with_columns([\n",
        "    pl.Series(\"Last_buy_scaled\", X_scaled[:, 0]),\n",
        "    pl.Series(\"Frequency_scaled\", X_scaled[:, 1]),\n",
        "    pl.Series(\"Monetary_scaled\", X_scaled[:, 2])\n",
        "])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JigTHR4miEgm"
      },
      "source": [
        "Aqui hacemos un ultimo describe para ver como ha quedado el dataset, con todos los cambios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Pqz2DzoiEgm",
        "outputId": "5a1f726c-5c81-4395-d160-3cb5c8c3cc53"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWGRTYg2iEgq"
      },
      "outputs": [],
      "source": [
        "df.write_csv(\"data_cleaned(clustering).csv\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXGlvy5QiEgq"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "with open(\"datos_grouped(clustering).pkl\", \"wb\") as file:\n",
        "    pickle.dump(df, file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwbfuJ-bCxWJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_rfhnLMbB9Q7",
        "outputId": "153c4025-b76c-46f4-a3b5-271fcee35f33"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzx5yDQzDT70"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZcziK48EGGw",
        "outputId": "324b7b53-db2b-4061-fb81-27e2b68449d9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3zsGFp9GkBv"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "6AN7LR7lGo8W",
        "outputId": "5577d11c-f048-40ab-a5ec-9fc2c51f7c47"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "lab_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
